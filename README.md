# ğŸ™ï¸ Speech Emotion Recognition (SER) â€” PBL Project (Sem 4)

> **Project-Based Learning | Semester 4 Mid-Term**

---

## ğŸ“Œ Overview

This project implements a **Speech Emotion Recognition (SER)** system that classifies human emotions from audio signals using:

- Audio signal processing (`librosa`)
- Feature extraction (MFCCs, pitch, energy)
- Machine learning classifiers (Logistic Regression, Random Forest, MLP)

---

## ğŸ—‚ï¸ Project Structure

```
speech-emotion-recognition-pbl2/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ README.md               # Dataset info & download instructions
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_signal_processing_demo.ipynb   # Audio loading & visualization
â”‚   â””â”€â”€ 02_feature_extraction.ipynb       # MFCC extraction & EDA
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ audio_processing.py     # Load, normalize, denoise audio
â”‚   â”œâ”€â”€ feature_extraction.py   # MFCC, pitch, energy features
â”‚   â”œâ”€â”€ model.py                # Classifier definitions
â”‚   â””â”€â”€ train_eval.py           # Training loop & evaluation metrics
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ mid_term_presentation.html  # GitHub Pages site
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ›´ Quickstart

### 1. Clone the repo
```bash
git clone https://github.com/Sallly-coder/speech-emotion-recognition-pbl2.git
cd speech-emotion-recognition-pbl2
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

### 3. Download dataset
See `data/README.md` for instructions (RAVDESS / TESS).

### 4. Run training
```bash
python src/train_eval.py --data_dir data/ravdess_subset --emotions happy sad neutral
```

### 5. Explore notebooks
```bash
jupyter notebook notebooks/
```

---

## ğŸ¯ Emotions Targeted (Mid-Term)

| Label     | Code |
|-----------|------|
| Neutral   | 01   |
| Happy     | 03   |
| Sad       | 04   |
| Angry     | 05   |

*(RAVDESS emotion codes)*

---

## ğŸ“Š Mid-Term Results (Baseline)

| Model               | Accuracy |
|---------------------|----------|
| Logistic Regression | ~65â€“70%  |
| Random Forest       | ~70â€“75%  |
| MLP Classifier      | ~72â€“78%  |

> *Results on 3-emotion subset (happy/sad/neutral), MFCC mean+std features*

---

## ğŸ›£ï¸ Roadmap

- [x] **Sem 4 (Mid-Term):** Pipeline setup, MFCC extraction, baseline classifiers
- [ ] **Sem 5:** 1D-CNN / LSTM models, more emotions
- [ ] **Sem 6:** Real-time audio input
- [ ] **Sem 7-8:** Deployment, UI polish, report

---

## ğŸ”— Links

- **GitHub Pages / Presentation:** [Link here]
- **Dataset:** [RAVDESS on Kaggle](https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio)

---

## ğŸ“š References

- [Librosa Documentation](https://librosa.org/doc/)
- [RAVDESS Dataset](https://zenodo.org/record/1188976)
- [TechVidvan â€“ Speech Emotion Recognition](https://techvidvan.com/tutorials/python-project-speech-emotion-recognition/)
- Scikit-learn User Guide: https://scikit-learn.org/stable/
